---
title: "Analyses of Shrdlurn Data"
author: "Jesse Mu"
date: "3/20/2018"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(cowplot)
library(jsonlite)
knitr::opts_chunk$set(echo = TRUE)
```

# Process JSON files

```{r}
unrestricted = function(x) x %>% filter(mode == 'Unrestricted')
restricted = function(x) x %>% filter(mode == 'Restricted')

utts = do.call('rbind', lapply(list.files('data'), function(f) {
  f = paste0('data/', f)
  x = fromJSON(f)
  commands_df = data.frame(x$history)
  colnames(commands_df) = c('cStage', 'cLevelStep', 'cBits', 'cLevel', 'cUtterance')
  commands_df = commands_df %>%
    mutate(cStage = as.integer(as.character(cStage)),
           cLevelStep = as.integer(as.character(cLevelStep)),
           cBits = as.numeric(as.character(cBits)),
           cLevel = as.integer(as.character(cLevel)),
           cUtterance = as.character(cUtterance),
           cCharLen = length(cUtterance),
           cTokens = sapply(gregexpr("\\W+", cUtterance), length) + 1
    ) %>%
    filter(cUtterance != "") %>%
    mutate(
      id = x$id,
      tlxMentalDemand = x$tlx_mental_demand,
      # Reverse performance, so higher is better
      tlxPerformance = 100 - x$tlx_performance,
      tlxEffort = x$tlx_effort,
      tlxFrustration = x$tlx_frustration,
      mode = x$mode,
      numQueries = x$numQueries,
      totalChars = x$totalChars,
      totalTokens = x$totalTokens,
      numScrolls = x$numScrolls,
      numStatus = x$numStatus,
      cIndex = seq_along(cUtterance)
    ) %>%
    select(
      id, mode, numQueries, totalChars, totalTokens, numScrolls, numStatus, tlxMentalDemand, tlxPerformance, tlxEffort, tlxFrustration,
      cIndex, cUtterance, cStage, cLevelStep, cBits, cLevel, cCharLen, cTokens
    )
})) %>%
  mutate(
    mode = factor(ifelse(mode == 'restricted', 'Restricted', 'Unrestricted')),
    id = factor(id)
  )

# Create summary by removing the utterance-specific info
summ = utts %>%
  select(-starts_with('c')) %>%
  distinct %>%
  mutate(
    avgScrolls = numScrolls / numQueries
  )

max_penalty = utts %>%
  group_by(id) %>%
  summarise(max_penalty = max(cBits))

summ = summ %>%
  left_join(max_penalty, by = 'id')

tlx = summ %>%
  gather(tlxVariable, tlxValue, starts_with('tlx')) %>%
  mutate(tlxVariable = factor(substring(tlxVariable, 4)))
```

# Summary data

```{r}
summ %>%
  group_by(mode) %>%
  summarise(n = n())
```


# NASA TLX comparisons

```{r}
# T tests
tts = sapply(unique(tlx$tlxVariable), function(var) {
  tlx_ss = tlx %>% filter(tlxVariable == var)
  tlx_ss_r = tlx_ss %>% filter(mode == 'Restricted') %>% .$tlxValue
  tlx_ss_u = tlx_ss %>% filter(mode == 'Unrestricted') %>% .$tlxValue
  print(length(tlx_ss_r))
  print(length(tlx_ss_u))
  diff = mean(tlx_ss_r) - mean(tlx_ss_u)
  tt = coin::wilcox_test(y ~ x,
                    data = data.frame(
                      y = c(tlx_ss_r, tlx_ss_u),
                      x = factor(rep(0:1, c(length(tlx_ss_r), length(tlx_ss_u))))),
                    distribution = 'exact',
                    ties.method = 'mid-ranks')
  c(as.character(var), mean(tlx_ss_r), sd(tlx_ss_r), mean(tlx_ss_u), sd(tlx_ss_u), diff,
    coin::pvalue(tt),
    tt@statistic@linearstatistic - (8*(8+1)/2))
}) %>%
  t %>%
  as.data.frame %>%
  mutate(
    V2 = as.numeric(as.character(V2)),
    V3 = as.numeric(as.character(V3)),
    V4 = as.numeric(as.character(V4)),
    V5 = as.numeric(as.character(V5)),
    V6 = as.numeric(as.character(V6)),
    V7 = as.numeric(as.character(V7)),
    V8 = as.numeric(as.character(V8))
  )
colnames(tts) = c('tlxVariable', 'r', 'r_sd', 'u', 'u_sd', 'diff', 'p', 'U')
tts = tts %>%
  mutate(signif = p < 0.05,
         tlxVariable = as.character(tlxVariable)) %>%
  tbl_df %>%
  mutate(
    label = ifelse(signif,
                   paste0("italic(p)==", sprintf('%.3f', p), "*\"*\""),
                   #ifelse(p < 0.10,
                          #paste0("italic(p)==", round(p, 3), "^\"\u2020\""),
                          paste0("italic(p)==", sprintf('%.3f', p)))

    # label = ifelse(signif,
    #                paste0("italic(t(", round(df, 1), "))==", round(t, 2), "~~italic(p)==", round(p, 3), "*\"*\""),
    #                paste0("italic(t(", round(df, 1), "))==", round(t, 2), "~~italic(p)==", round(p, 3)))
  )
```


```{r}
p = ggplot(tlx %>% mutate(tlxVariable = as.character(tlxVariable)), aes(x = mode, y = tlxValue, fill = mode)) +
  geom_text(data = tts, mapping = aes(x = NULL, y = NULL, label = label, fill = NULL), x = 1.5, y = 10, parse = TRUE) +
  facet_wrap(~ tlxVariable) +
  geom_boxplot() +
  guides(fill = FALSE) +
  xlab('') +
  ylab('Score') +
  scale_y_continuous(limits = c(0, 100), breaks = c(0, 20, 40, 60, 80, 100))
save_plot("~/Desktop/tlx_results.pdf", p, base_height = 4.5)
p
```

# Language comparisons

```{r}
p = ggplot(summ, aes(x = mode, y = avgScrolls, fill = mode)) +
  guides(fill = FALSE) +
  xlab('') +
  ylab('Mean scrolls/utterance') +
  geom_boxplot() +
  annotate('text', x = 1.5, y = 1, label = 'italic(p)==0.13', parse = TRUE) +
  scale_y_continuous(limits = c(0, 30), breaks = c(0, 10, 20, 30))
save_plot("~/Dropbox/Cambridge/R230/Report/avg_scrolls.pdf", p, base_aspect_ratio = 1.25, base_height = 3)
p
```

```{r}
perf_corr = summ %>% left_join(distincts %>% select(id, n_distinct))%>%
  # filter(mode == 'Unrestricted') %>%
  # gather('Measure', 'Value', starts_with('tlx'), avgScrolls)
  gather('Measure', 'Value', starts_with('tlx')) %>%
  mutate(Measure = factor(substring(Measure, 4)))

perf_corr_t = perf_corr %>%
  group_by(mode, Measure) %>%
  summarise(r = cor(avgScrolls, Value),
         p = cor.test(avgScrolls, Value)$p.value) %>%
  mutate(label = paste0("italic(r)==", round(r, 2), "~~italic(p)==", round(p, 2)))

p = ggplot(perf_corr, aes(x = avgScrolls, y = Value, color = mode)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  guides(color = FALSE) +
  facet_grid(mode ~ Measure) +
  xlab('Mean Scrolls/Utterance') +
  ylab('Score') +
  scale_y_continuous(limits = c(0, 100), breaks = c(0, 25, 50, 75, 100)) +
  geom_text(data = perf_corr_t, aes(x = NULL, y = NULL, color = NULL, label = label), x = 15, y = 10, parse = TRUE)
save_plot("~/Dropbox/Cambridge/R230/Report/perf_corr.pdf", p, base_aspect_ratio = 1.9, base_height = 3.5)
p
```

```{r}
lang_corr = summ %>%
  left_join(distincts %>% select(id, n_distinct)) %>%
  left_join(utts %>% group_by(id, mode) %>% summarise(`Mean Utterance Length` = mean(cTokens))) %>%
  filter(mode == 'Unrestricted') %>%
  rename(`Distinct Tokens` = n_distinct) %>%
  gather('LangProperty', 'Value', `Distinct Tokens`, `Mean Utterance Length`)
  # gather('Measure', 'Value', starts_with('tlx'), avgScrolls)
  # gather('Measure', 'Value', starts_with('tlx')) %>%
  # mutate(Measure = factor(substring(Measure, 4)))

lang_corr_t = lang_corr %>%
  group_by(LangProperty) %>%
  summarise(r = cor(avgScrolls, Value),
         p = cor.test(avgScrolls, Value)$p.value) %>%
  mutate(label = paste0("italic(r)==", round(r, 2), "~~italic(p)==", round(p, 2))) %>%
  mutate(
    x = ifelse(LangProperty == 'Distinct Tokens', 29, 5.1),
    y = 0
  )

p = ggplot(lang_corr, aes(y = avgScrolls, x = Value)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  guides(color = FALSE) +
  facet_wrap(~ LangProperty, scales = 'free_x') +
  xlab('') +
  ylab('Mean Scrolls/Utterance') +
  geom_text(data = lang_corr_t, aes(x = x, y = y, color = NULL, label = label), parse = TRUE) +
save_plot("~/Dropbox/Cambridge/R230/Report/lang_corr.pdf", p, base_aspect_ratio = 1.9, base_height = 3.5)
p
```



```{r}
ggplot(summ, aes(x = mode, y = max_penalty)) +
  geom_boxplot()
```

```{r}
ggplot(utts, aes(x = cIndex, y = cTokens, color = mode, group = id)) +
  facet_wrap(~ mode) +
  geom_line() +
  xlab('Utterance') +
  guides(color = FALSE) +
  ylab('Utterance length')
```

# Wordclouds

```{r}
library(tm)
rCorpus = SimpleCorpus(VectorSource(utts %>% filter(mode == 'Restricted') %>% .$cUtterance),
                       control = list(language = 'en'))
uCorpus = SimpleCorpus(VectorSource(utts %>% filter(mode == 'Unrestricted') %>% .$cUtterance),
                       control = list(language = 'en'))
```

```{r}
library(RColorBrewer)
library(wordcloud)
pdf('~/Dropbox/Cambridge/R230/Report/wc_r.pdf')
wordcloud::wordcloud(rCorpus, colors = brewer.pal(8, 'Dark2'), min.freq = 1)
dev.off()
pdf('~/Dropbox/Cambridge/R230/Report/wc_u.pdf')
wordcloud::wordcloud(uCorpus, colors = brewer.pal(8, 'Dark2'), min.freq = 1)
dev.off()
```

```{r}
r_tokens = utts %>% filter(mode == 'Restricted') %>% .$cTokens
u_tokens = utts %>% filter(mode == 'Unrestricted') %>% .$cTokens
# t.test(r_tokens, u_tokens)
wilcox.test(r_tokens, u_tokens)
```

```{r}
nutt = utts %>% group_by(id, mode) %>% summarise(n = n(), cTokens = mean(cTokens))
r_nutt = utts %>% filter(mode == 'Restricted') %>% .$cTokens
u_nutt = utts %>% filter(mode == 'Unrestricted') %>% .$cTokens
t.test(r_nutt, u_nutt)
```

```{r}
distincts = utts %>%
  group_by(id, mode) %>%
  summarise(all_utts = paste(cUtterance, sep = '', collapse = ' ')) %>%
  mutate(n_distinct = sapply(strsplit(all_utts, " "), function(x) length(unique(x))) %>% unlist)
r_distinct = distincts %>% filter(mode == 'Restricted') %>% .$n_distinct
u_distinct = distincts %>% filter(mode == 'Unrestricted') %>% .$n_distinct
t.test(r_distinct, u_distinct)
```

```{r}
r_scrolls = summ %>% filter(mode == 'Restricted') %>% .$avgScrolls
u_scrolls = summ %>% filter(mode == 'Unrestricted') %>% .$avgScrolls
t.test(r_scrolls, u_scrolls)
```

# Examine example utterances of high/low-performing players

```{r}
summ %>%
  unrestricted %>%
  arrange(avgScrolls)
```

```{r}
utts %>% filter(id == 'v7iva6hv') %>%
  select(starts_with('c'))
```



